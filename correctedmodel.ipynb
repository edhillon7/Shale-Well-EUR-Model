{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abcf4a6-d292-48fa-8360-675e71591af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f464ec9-0524-4289-96f0-b9a7d0ef4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv('Chapter2_Shale_Gas_Wells_DataSet.csv')\n",
    "        \n",
    "        # Separate features (X) and target (Z)\n",
    "        X = df.iloc[:, :13]  # Selecting the first 13 columns as features\n",
    "        Z = df.iloc[:, -2]   # Selecting the second-to-last column as the target variable\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Create and train the model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_scaled, Z_train)\n",
    "        \n",
    "        # Save the model and scaler for later use\n",
    "        joblib.dump(model, 'linear_regression_model.pkl')\n",
    "        joblib.dump(scaler, 'scaler.pkl')\n",
    "        \n",
    "        # Evaluate the model\n",
    "        Z_pred = model.predict(X_test_scaled)\n",
    "        mse = mean_squared_error(Z_test, Z_pred)\n",
    "        mae = mean_absolute_error(Z_test, Z_pred)\n",
    "        r2 = r2_score(Z_test, Z_pred)\n",
    "        \n",
    "        print(f\"Training Complete\\nMSE: {mse}, MAE: {mae}, R2: {r2}\")\n",
    "        return {\"mse\": mse, \"mae\": mae, \"r2\": r2}\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Dataset file not found.\")\n",
    "        return {\"error\": \"Dataset file not found\"}\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during training: {e}\")\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc45008d-1d78-463a-86ca-2ca0adcc7a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n",
      "MSE: 2.4961007206907646, MAE: 1.0897426619568948, R2: 0.6982202815810612\n",
      "{'mse': 2.4961007206907646, 'mae': 1.0897426619568948, 'r2': 0.6982202815810612}\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save the trained model and scaler\n",
    "metrics = train_model()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd358860-8984-4621-90f5-bc26cf812fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_data):\n",
    "    model_path = 'linear_regression_model.pkl'\n",
    "    scaler_path = 'scaler.pkl'\n",
    "    \n",
    "    try:\n",
    "        # Check if the model and scaler files exist before loading\n",
    "        if not os.path.exists(model_path) or not os.path.exists(scaler_path):\n",
    "            return \"Model or scaler file not found. Please train the model first.\"\n",
    "\n",
    "        # Load the saved model and scaler\n",
    "        model = joblib.load(model_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        # Ensure input_data is in the correct shape for prediction\n",
    "        input_data = np.array(input_data).reshape(1, -1)  # Reshape for single prediction\n",
    "        input_data_scaled = scaler.transform(input_data)  # Scale input data\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(input_data_scaled)\n",
    "        return prediction[0]  # Return the predicted value\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during prediction: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2416156b-29eb-48e0-9d10-53f515f72a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted EUR: 10.53509976460328 Bbl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test the prediction function with sample input data\n",
    "sample_input_data = [\n",
    "    1000, 5, 1200, 30, 150, 8000, 25, 10, 5000, 30, 40, 0.8, 20\n",
    "]\n",
    "\n",
    "prediction = predict(sample_input_data)\n",
    "print(f\"Predicted EUR: {prediction} Bbl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e68d3-2e26-4b5a-855b-170d91a92450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
